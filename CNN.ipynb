{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMcB34+UgnABstVIMmLpj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arminhosseini/CNN_mnist/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4QCYzu-48Uh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeHaclUF5fqD"
      },
      "source": [
        "num_classes = 10 # total classe (0-9 digits)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_steps = 200\n",
        "batch_size = 128\n",
        "display_steps = 10\n",
        "\n",
        "\n",
        "conv1_filters = 32 # number of filters for the first conv layer\n",
        "conv2_filters = 64 # number of filters for the second conv layer\n",
        "fcl_units = 1024 # number of neurons for the fully connected layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iuxy64v7SZC"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train) , (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL4kFhui8q7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27aa6a58-5a87-41b8-89fb-532456d1994c"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
        "print(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 28, 28), (None,)), types: (tf.float32, tf.uint8)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRuUWG8f9yTp"
      },
      "source": [
        "class ConvNet(Model):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    self.conv1 = layers.Conv2D(32, kernel_size=5, activation=tf.nn.relu)\n",
        "\n",
        "    self.maxpool1 = layers.MaxPool2D(2, strides=2)\n",
        "\n",
        "    self.conv2 = layers.Conv2D(64, kernel_size=3, activation=tf.nn.relu)\n",
        "\n",
        "    self.maxpool2 = layers.MaxPool2D(2, strides=2)\n",
        "\n",
        "    self.flatten = layers.Flatten()\n",
        "\n",
        "    self.fc1 = layers.Dense(1024)\n",
        "\n",
        "    self.dropout = layers.Dropout(rate = 0.2)\n",
        "\n",
        "    self.fc2 = layers.Dense(2048)\n",
        "\n",
        "    self.dropout2 = layers.Dropout(rate = 0.5)\n",
        "\n",
        "    self.out = layers.Dense(num_classes)\n",
        "\n",
        "\n",
        "  def call (self, x, is_training = False):\n",
        "    x = tf.reshape(x, [-1,28,28,1])\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.dropout(x, training = is_training)\n",
        "    x = self.fc2(x)\n",
        "    x = self.dropout2(x, training = is_training)\n",
        "    x = self.out(x)\n",
        "\n",
        "\n",
        "    if not is_training:\n",
        "      x = tf.nn.softmax(x)\n",
        "\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "conv_net = ConvNet()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w82z0O5bGIsL"
      },
      "source": [
        "def cross_entropy_loss(x,y):\n",
        "  y = tf.cast(y, tf.int64)\n",
        "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
        "\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY90tBTRDlRH"
      },
      "source": [
        "## optimization process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsP9P7M0Da8c"
      },
      "source": [
        "@tf.function\n",
        "def run_optimization(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    pred = conv_net(x, is_training = True)\n",
        "    loss = cross_entropy_loss(pred, y)\n",
        "\n",
        "  trainable_variables = conv_net.trainable_variables\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients,trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIGlmz9HJ0V7"
      },
      "source": [
        "## Run training for the given number of steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNVHwjaxJT8r",
        "outputId": "7d950085-d7c8-468c-d92b-5fcf2b0e1b36"
      },
      "source": [
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
        "  run_optimization(batch_x, batch_y)\n",
        "\n",
        "  if step % display_steps == 0:\n",
        "    pred = conv_net(batch_x)\n",
        "    loss = cross_entropy_loss(pred, batch_y)\n",
        "    acc = accuracy(pred, batch_y)\n",
        "    print('step: %i, loss: %f, accuracy: %f'%(step, loss, acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 10, loss: 1.665745, accuracy: 0.851562\n",
            "step: 20, loss: 1.600651, accuracy: 0.914062\n",
            "step: 30, loss: 1.573416, accuracy: 0.921875\n",
            "step: 40, loss: 1.529433, accuracy: 0.968750\n",
            "step: 50, loss: 1.528706, accuracy: 0.945312\n",
            "step: 60, loss: 1.530127, accuracy: 0.953125\n",
            "step: 70, loss: 1.496995, accuracy: 0.984375\n",
            "step: 80, loss: 1.513624, accuracy: 0.984375\n",
            "step: 90, loss: 1.518759, accuracy: 0.968750\n",
            "step: 100, loss: 1.490051, accuracy: 0.984375\n",
            "step: 110, loss: 1.499300, accuracy: 0.984375\n",
            "step: 120, loss: 1.506107, accuracy: 0.976562\n",
            "step: 130, loss: 1.514315, accuracy: 0.960938\n",
            "step: 140, loss: 1.488542, accuracy: 0.984375\n",
            "step: 150, loss: 1.473086, accuracy: 1.000000\n",
            "step: 160, loss: 1.510468, accuracy: 0.968750\n",
            "step: 170, loss: 1.516033, accuracy: 0.960938\n",
            "step: 180, loss: 1.510814, accuracy: 0.968750\n",
            "step: 190, loss: 1.513747, accuracy: 0.960938\n",
            "step: 200, loss: 1.485455, accuracy: 0.992188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SDhhaUTPwQo",
        "outputId": "dc6682c3-9216-40b5-d75b-5ad013da98d4"
      },
      "source": [
        "pred = conv_net(x_test)\n",
        "\n",
        "print('test accuracy: %f' % accuracy(pred, y_test ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.977800\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}